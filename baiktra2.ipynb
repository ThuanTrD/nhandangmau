{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3LDZtlw4X9v",
        "outputId": "391fbc6d-8baf-42a2-9577-d140ed7a4088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Loss = 0.0097\n",
            "Epoch 40, Loss = 0.0020\n",
            "Epoch 60, Loss = 0.0010\n",
            "Epoch 80, Loss = 0.0007\n",
            "Epoch 100, Loss = 0.0007\n",
            "\n",
            "=== KẾT QUẢ DỰ ĐOÁN ===\n",
            "Từ gốc: deep          →  Dự đoán từ kế tiếp: learning\n",
            "Từ gốc: learning      →  Dự đoán từ kế tiếp: transforms\n",
            "Từ gốc: transforms    →  Dự đoán từ kế tiếp: the\n",
            "Từ gốc: the           →  Dự đoán từ kế tiếp: world\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ==== 1. DỮ LIỆU MẪU ====\n",
        "text = \"deep learning transforms the world\"\n",
        "vocab = list(set(text.split()))\n",
        "word2idx = {w: i for i, w in enumerate(vocab)}\n",
        "idx2word = {i: w for w, i in word2idx.items()}\n",
        "\n",
        "data = [word2idx[w] for w in text.split()]\n",
        "inputs  = torch.tensor([data[:-1]])   # [\"deep\", \"learning\", \"transforms\", \"the\"]\n",
        "targets = torch.tensor([data[1:]])    # [\"learning\", \"transforms\", \"the\", \"world\"]\n",
        "\n",
        "# ==== 2. MÔ HÌNH TRANSFORMER ====\n",
        "class TinyTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=32, nhead=4, num_layers=2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=nhead, batch_first=True\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = self.encoder(x)\n",
        "        out = self.fc(x)\n",
        "        return out\n",
        "\n",
        "# ==== 3. KHỞI TẠO, HÀM MẤT MÁT, TỐI ƯU ====\n",
        "model = TinyTransformer(len(vocab))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# ==== 4. HUẤN LUYỆN ===='\n",
        "for epoch in range(100):\n",
        "    optimizer.zero_grad()\n",
        "    output = model(inputs)\n",
        "    loss = criterion(output.view(-1, len(vocab)), targets.view(-1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        print(f\"Epoch {epoch+1}, Loss = {loss.item():.4f}\")\n",
        "\n",
        "# ==== 5. IN RA DỰ ĐOÁN ====\n",
        "with torch.no_grad():\n",
        "    preds = model(inputs)\n",
        "    predicted_indices = preds.argmax(dim=-1).squeeze().tolist()\n",
        "    predicted_words = [idx2word[i] for i in predicted_indices]\n",
        "\n",
        "print(\"\\n=== KẾT QUẢ DỰ ĐOÁN ===\")\n",
        "for i, (inp, pred) in enumerate(zip(inputs.squeeze(), predicted_words)):\n",
        "    print(f\"Từ gốc: {idx2word[inp.item()]:<12}  →  Dự đoán từ kế tiếp: {pred}\")\n"
      ]
    }
  ]
}